# Deep Learning Image Preprocessing Module

ËøôÊòØ‰∏Ä‰∏™ÂäüËÉΩÂº∫Â§ß„ÄÅÊ®°ÂùóÂåñÁöÑÊ∑±Â∫¶Â≠¶‰π†ÂõæÂÉèÈ¢ÑÂ§ÑÁêÜÁ≥ªÁªüÔºå‰∏ì‰∏∫Ê∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÁöÑËæìÂÖ•Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜËÄåËÆæËÆ°„ÄÇËØ•Ê®°ÂùóÊèê‰æõ‰∫ÜÁÅµÊ¥ªÁöÑÈÖçÁΩÆÈÄâÈ°π„ÄÅÂèØÁªÑÂêàÁöÑÂèòÊç¢Êìç‰ΩúÂíåÈ´òÊÄßËÉΩÁöÑÊâπÂ§ÑÁêÜËÉΩÂäõ„ÄÇ

## ‰∏ªË¶ÅÁâπÊÄß

### üöÄ Ê†∏ÂøÉÂäüËÉΩ
- **Ê®°ÂùóÂåñËÆæËÆ°**: ÊØè‰∏™È¢ÑÂ§ÑÁêÜÊìç‰ΩúÈÉΩÊòØÁã¨Á´ãÁöÑÂèòÊç¢Á±ªÔºåÂèØ‰ª•ÂçïÁã¨‰ΩøÁî®ÊàñÁªÑÂêà‰ΩøÁî®
- **ÈÖçÁΩÆÈ©±Âä®**: ÈÄöËøáÈÖçÁΩÆÁ±ªÁÆ°ÁêÜÊâÄÊúâÈ¢ÑÂ§ÑÁêÜÂèÇÊï∞ÔºåÊîØÊåÅÈÖçÁΩÆÊñá‰ª∂ÁöÑ‰øùÂ≠òÂíåÂä†ËΩΩ
- **ÁÆ°ÈÅìÁªÑÂêà**: ÊîØÊåÅÂ∞ÜÂ§ö‰∏™ÂèòÊç¢Êìç‰ΩúÁªÑÂêàÊàêÈ¢ÑÂ§ÑÁêÜÁÆ°ÈÅì
- **ÊâπÂ§ÑÁêÜÊîØÊåÅ**: È´òÊïàÁöÑÊâπÈáèÂõæÂÉèÂ§ÑÁêÜËÉΩÂäõ
- **ÊÄßËÉΩÁõëÊéß**: ÂÜÖÁΩÆÊó∂Èó¥ÁªüËÆ°ÂäüËÉΩÔºåÂ∏ÆÂä©‰ºòÂåñÈ¢ÑÂ§ÑÁêÜÊÄßËÉΩ
- **ÈîôËØØÂ§ÑÁêÜ**: ÂÆåÂñÑÁöÑÂºÇÂ∏∏Â§ÑÁêÜÊú∫Âà∂ÔºåÊèê‰æõËØ¶ÁªÜÁöÑÈîôËØØ‰ø°ÊÅØ

### üîß ÊîØÊåÅÁöÑÂèòÊç¢Êìç‰Ωú
- **ÂõæÂÉèÁº©Êîæ**: ÊîØÊåÅÂ§öÁßçÊèíÂÄºÊñπÊ≥ïÔºåÂèØ‰øùÊåÅÂÆΩÈ´òÊØî
- **ÂΩí‰∏ÄÂåñ**: ÊîØÊåÅÊ†áÂáÜÂΩí‰∏ÄÂåñ„ÄÅÊúÄÂ∞è-ÊúÄÂ§ßÁº©ÊîæÁ≠â
- **Êï∞ÊçÆÁ±ªÂûãËΩ¨Êç¢**: ÂÆâÂÖ®ÁöÑÊï∞ÊçÆÁ±ªÂûãËΩ¨Êç¢ÔºåÊîØÊåÅÂÄºÂüüÁº©Êîæ
- **Â°´ÂÖÖ**: Â§öÁßçÂ°´ÂÖÖÊ®°ÂºèÔºàÂ∏∏Êï∞„ÄÅÂèçÂ∞Ñ„ÄÅÂ§çÂà∂Á≠âÔºâ
- **Ë£ÅÂâ™**: ‰∏≠ÂøÉË£ÅÂâ™„ÄÅÊåáÂÆöÂå∫ÂüüË£ÅÂâ™
- **È¢úËâ≤Ê†ºÂºèËΩ¨Êç¢**: BGR„ÄÅRGB„ÄÅÁÅ∞Â∫¶Âõæ‰πãÈó¥ÁöÑËΩ¨Êç¢

## Âø´ÈÄüÂºÄÂßã

### Âü∫Êú¨‰ΩøÁî®

```python
import numpy as np
from hailo_toolbox.process import ImagePreprocessor, PreprocessConfig

# ÂàõÂª∫ÈÖçÁΩÆ
config = PreprocessConfig(
    target_size=(224, 224),          # ÁõÆÊ†áÂ∞∫ÂØ∏
    normalize=True,                  # ÂêØÁî®ÂΩí‰∏ÄÂåñ
    mean=[0.485, 0.456, 0.406],     # ImageNetÂùáÂÄº
    std=[0.229, 0.224, 0.225],      # ImageNetÊ†áÂáÜÂ∑Æ
    scale=1.0/255.0,                # Áº©ÊîæÂõ†Â≠ê
    input_format="BGR",             # ËæìÂÖ•Ê†ºÂºè
    output_format="RGB"             # ËæìÂá∫Ê†ºÂºè
)

# ÂàõÂª∫È¢ÑÂ§ÑÁêÜÂô®
preprocessor = ImagePreprocessor(config)

# Â§ÑÁêÜÂõæÂÉè
image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
processed_image = preprocessor(image)

print(f"ÂéüÂßãÂõæÂÉè: {image.shape}, {image.dtype}")
print(f"Â§ÑÁêÜÂêé: {processed_image.shape}, {processed_image.dtype}")
```

### Ëá™ÂÆö‰πâÁÆ°ÈÅì

```python
from hailo_toolbox.process import (
    ResizeTransform, NormalizationTransform, 
    PreprocessPipeline
)

# ÂàõÂª∫Ëá™ÂÆö‰πâÂèòÊç¢
resize_transform = ResizeTransform(
    target_size=(416, 416),
    interpolation="LINEAR",
    preserve_aspect_ratio=True
)

normalize_transform = NormalizationTransform(
    mean=127.5,
    std=127.5,
    scale=1.0,
    dtype=np.float32
)

# ÂàõÂª∫ÁÆ°ÈÅì
pipeline = PreprocessPipeline(
    transforms=[resize_transform, normalize_transform],
    name="YOLO_Preprocessing",
    enable_timing=True
)

# Â§ÑÁêÜÂõæÂÉè
result = pipeline(image)
pipeline.print_timing_stats()
```

## ËØ¶ÁªÜÈÖçÁΩÆÈÄâÈ°π

### PreprocessConfig ÂèÇÊï∞ËØ¥Êòé

```python
@dataclass
class PreprocessConfig:
    # Áº©ÊîæÂèÇÊï∞
    target_size: Optional[Tuple[int, int]] = None  # ÁõÆÊ†áÂ∞∫ÂØ∏ (width, height)
    interpolation: str = "LINEAR"                   # ÊèíÂÄºÊñπÊ≥ï: NEAREST, LINEAR, CUBIC, AREA, LANCZOS4
    preserve_aspect_ratio: bool = False             # ÊòØÂê¶‰øùÊåÅÂÆΩÈ´òÊØî
    
    # ÂΩí‰∏ÄÂåñÂèÇÊï∞
    normalize: bool = True                          # ÊòØÂê¶ÂêØÁî®ÂΩí‰∏ÄÂåñ
    mean: Union[float, List[float]] = 0.0          # ÂùáÂÄº
    std: Union[float, List[float]] = 1.0           # Ê†áÂáÜÂ∑Æ
    scale: float = 1.0                             # Áº©ÊîæÂõ†Â≠ê
    
    # Êï∞ÊçÆÁ±ªÂûãÂèÇÊï∞
    target_dtype: Optional[str] = None             # ÁõÆÊ†áÊï∞ÊçÆÁ±ªÂûã
    scale_values: bool = True                      # ÊòØÂê¶Áº©ÊîæÂÄºÂüü
    clip_values: bool = True                       # ÊòØÂê¶Ë£ÅÂâ™ÂÄºÂüü
    
    # Â°´ÂÖÖÂèÇÊï∞
    padding: Optional[Union[int, Tuple]] = None    # Â°´ÂÖÖÂ§ßÂ∞è
    padding_mode: str = "CONSTANT"                 # Â°´ÂÖÖÊ®°Âºè
    padding_value: Union[int, float] = 0           # Â°´ÂÖÖÂÄº
    
    # Ë£ÅÂâ™ÂèÇÊï∞
    crop_size: Optional[Tuple[int, int]] = None    # Ë£ÅÂâ™Â∞∫ÂØ∏
    crop_region: Optional[Tuple[int, int, int, int]] = None  # Ë£ÅÂâ™Âå∫Âüü
    center_crop: bool = True                       # ÊòØÂê¶‰∏≠ÂøÉË£ÅÂâ™
    
    # ÁÆ°ÈÅìÂèÇÊï∞
    enable_timing: bool = False                    # ÊòØÂê¶ÂêØÁî®Êó∂Èó¥ÁªüËÆ°
    pipeline_name: str = "ImagePreprocessor"      # ÁÆ°ÈÅìÂêçÁß∞
    
    # È¢úËâ≤Ê†ºÂºè
    input_format: str = "BGR"                      # ËæìÂÖ•Ê†ºÂºè: BGR, RGB, GRAY
    output_format: str = "RGB"                     # ËæìÂá∫Ê†ºÂºè: BGR, RGB, GRAY
```

## ‰ΩøÁî®Âú∫ÊôØÁ§∫‰æã

### 1. ImageNet ÂàÜÁ±ªÊ®°ÂûãÈ¢ÑÂ§ÑÁêÜ

```python
# ResNet/VGG Á≠âÊ®°ÂûãÁöÑÊ†áÂáÜÈ¢ÑÂ§ÑÁêÜ
config = PreprocessConfig(
    target_size=(224, 224),
    normalize=True,
    mean=[0.485, 0.456, 0.406],
    std=[0.229, 0.224, 0.225],
    scale=1.0/255.0,
    input_format="BGR",
    output_format="RGB"
)
```

### 2. YOLO ÁõÆÊ†áÊ£ÄÊµãÈ¢ÑÂ§ÑÁêÜ

```python
# YOLO Ê®°ÂûãÁöÑÈ¢ÑÂ§ÑÁêÜÈÖçÁΩÆ
config = PreprocessConfig(
    target_size=(416, 416),
    preserve_aspect_ratio=True,
    normalize=True,
    mean=0.0,
    std=255.0,
    scale=1.0,
    target_dtype="float32"
)
```

### 3. ËØ≠‰πâÂàÜÂâ≤Ê®°ÂûãÈ¢ÑÂ§ÑÁêÜ

```python
# ËØ≠‰πâÂàÜÂâ≤Ê®°ÂûãÁöÑÈ¢ÑÂ§ÑÁêÜÈÖçÁΩÆ
config = PreprocessConfig(
    target_size=(512, 512),
    interpolation="CUBIC",
    normalize=True,
    mean=[0.5, 0.5, 0.5],
    std=[0.5, 0.5, 0.5],
    scale=1.0/255.0,
    padding=(10, 10),
    padding_mode="REFLECT"
)
```

### 4. ÊâπÈáèÂ§ÑÁêÜ

```python
# ÊâπÈáèÂ§ÑÁêÜÂ§öÂº†ÂõæÂÉè
images = [image1, image2, image3, image4]
processed_images = preprocessor.process_batch(images)

# Êàñ‰ΩøÁî®ÁÆ°ÈÅìÊâπÈáèÂ§ÑÁêÜ
processed_images = pipeline.process_batch(images)
```

## ÈÖçÁΩÆÁÆ°ÁêÜ

### ‰øùÂ≠òÂíåÂä†ËΩΩÈÖçÁΩÆ

```python
# ‰øùÂ≠òÈÖçÁΩÆÂà∞Êñá‰ª∂
config.save("preprocessing_config.json")

# ‰ªéÊñá‰ª∂Âä†ËΩΩÈÖçÁΩÆ
loaded_config = PreprocessConfig.load("preprocessing_config.json")

# ‰ªéÈÖçÁΩÆÊñá‰ª∂ÂàõÂª∫È¢ÑÂ§ÑÁêÜÂô®
preprocessor = ImagePreprocessor.from_config_file("preprocessing_config.json")
```

### Âä®ÊÄÅÊõ¥Êñ∞ÈÖçÁΩÆ

```python
# Âä®ÊÄÅÊõ¥Êñ∞È¢ÑÂ§ÑÁêÜÂô®ÈÖçÁΩÆ
preprocessor.update_config(
    target_size=(256, 256),
    normalize=False,
    enable_timing=True
)
```

## ÊÄßËÉΩÁõëÊéß

### ÂêØÁî®Êó∂Èó¥ÁªüËÆ°

```python
# Âú®ÈÖçÁΩÆ‰∏≠ÂêØÁî®Êó∂Èó¥ÁªüËÆ°
config = PreprocessConfig(enable_timing=True)
preprocessor = ImagePreprocessor(config)

# ÊàñÂú®ÁÆ°ÈÅì‰∏≠ÂêØÁî®
pipeline = PreprocessPipeline(transforms, enable_timing=True)

# Â§ÑÁêÜÂõæÂÉèÂêéÊü•ÁúãÁªüËÆ°‰ø°ÊÅØ
preprocessor.print_timing_stats()
```

### Êó∂Èó¥ÁªüËÆ°ËæìÂá∫Á§∫‰æã

```
Timing Statistics for Pipeline: ImagePreprocessor
----------------------------------------------------------------------
Transform                 Calls    Total (s)    Avg (s)    
----------------------------------------------------------------------
ResizeTransform           100      0.1234       0.0012     
NormalizationTransform    100      0.0567       0.0006     
----------------------------------------------------------------------
TOTAL                     200      0.1801       0.0009     
----------------------------------------------------------------------
```

## ÈîôËØØÂ§ÑÁêÜ

ËØ•Ê®°ÂùóÊèê‰æõ‰∫ÜÂÆåÂñÑÁöÑÈîôËØØÂ§ÑÁêÜÊú∫Âà∂Ôºö

```python
from hailo_toolbox.process import PreprocessError, InvalidConfigError

try:
    # Êó†ÊïàÈÖçÁΩÆ
    config = PreprocessConfig(target_size=(0, 224))
except InvalidConfigError as e:
    print(f"ÈÖçÁΩÆÈîôËØØ: {e}")
    print(f"ÈîôËØØÂ≠óÊÆµ: {e.config_field}")
    print(f"Êèê‰æõÁöÑÂÄº: {e.provided_value}")

try:
    # Â§ÑÁêÜÊó†ÊïàËæìÂÖ•
    result = preprocessor("not an image")
except PreprocessError as e:
    print(f"Â§ÑÁêÜÈîôËØØ: {e}")
    print(f"ÈîôËØØËØ¶ÊÉÖ: {e.details}")
```

## Êâ©Â±ïÊÄß

### Ëá™ÂÆö‰πâÂèòÊç¢

```python
from hailo_toolbox.process.transforms import BaseTransform

class CustomTransform(BaseTransform):
    def __init__(self, param1, param2, name=None):
        super().__init__(name)
        self.param1 = param1
        self.param2 = param2
    
    def __call__(self, image):
        self.validate_image(image)
        # ÂÆûÁé∞Ëá™ÂÆö‰πâÂèòÊç¢ÈÄªËæë
        return processed_image
    
    def get_config(self):
        return {
            "param1": self.param1,
            "param2": self.param2,
            "name": self.name
        }

# ‰ΩøÁî®Ëá™ÂÆö‰πâÂèòÊç¢
custom_transform = CustomTransform(param1="value1", param2="value2")
pipeline = PreprocessPipeline([custom_transform])
```

## ÊúÄ‰Ω≥ÂÆûË∑µ

### 1. ÊÄßËÉΩ‰ºòÂåñ
- ÂØπ‰∫éÊâπÈáèÂ§ÑÁêÜÔºå‰ΩøÁî® `process_batch()` ÊñπÊ≥ï
- ÂêØÁî®Êó∂Èó¥ÁªüËÆ°Êù•ËØÜÂà´ÊÄßËÉΩÁì∂È¢à
- Ê†πÊçÆÊ®°ÂûãÈúÄÊ±ÇÈÄâÊã©ÂêàÈÄÇÁöÑÊèíÂÄºÊñπÊ≥ï

### 2. ÂÜÖÂ≠òÁÆ°ÁêÜ
- ÂØπ‰∫éÂ§ßÂõæÂÉèÔºåËÄÉËôëÂÖàË£ÅÂâ™ÂÜçÁº©Êîæ
- ‰ΩøÁî®ÈÄÇÂΩìÁöÑÊï∞ÊçÆÁ±ªÂûã‰ª•ËäÇÁúÅÂÜÖÂ≠ò

### 3. ÈÖçÁΩÆÁÆ°ÁêÜ
- ‰∏∫‰∏çÂêåÊ®°ÂûãÂàõÂª∫‰∏ìÈó®ÁöÑÈÖçÁΩÆÊñá‰ª∂
- ‰ΩøÁî®ÊúâÊÑè‰πâÁöÑÁÆ°ÈÅìÂêçÁß∞‰æø‰∫éË∞ÉËØï

### 4. ÈîôËØØÂ§ÑÁêÜ
- ÂßãÁªà‰ΩøÁî® try-catch ÂùóÂ§ÑÁêÜÈ¢ÑÂ§ÑÁêÜÊìç‰Ωú
- Ê£ÄÊü•ËæìÂÖ•ÂõæÂÉèÁöÑÊ†ºÂºèÂíåÂ∞∫ÂØ∏

## API ÂèÇËÄÉ

### ‰∏ªË¶ÅÁ±ª

- `ImagePreprocessor`: ‰∏ªË¶ÅÁöÑÈ¢ÑÂ§ÑÁêÜÂô®Á±ª
- `PreprocessConfig`: ÈÖçÁΩÆÁÆ°ÁêÜÁ±ª
- `PreprocessPipeline`: È¢ÑÂ§ÑÁêÜÁÆ°ÈÅìÁ±ª

### ÂèòÊç¢Á±ª

- `ResizeTransform`: ÂõæÂÉèÁº©ÊîæÂèòÊç¢
- `NormalizationTransform`: ÂΩí‰∏ÄÂåñÂèòÊç¢
- `DataTypeTransform`: Êï∞ÊçÆÁ±ªÂûãËΩ¨Êç¢ÂèòÊç¢
- `PaddingTransform`: Â°´ÂÖÖÂèòÊç¢
- `CropTransform`: Ë£ÅÂâ™ÂèòÊç¢

### ÂºÇÂ∏∏Á±ª

- `PreprocessError`: Âü∫Á°ÄÈ¢ÑÂ§ÑÁêÜÂºÇÂ∏∏
- `InvalidConfigError`: Êó†ÊïàÈÖçÁΩÆÂºÇÂ∏∏
- `ImageProcessingError`: ÂõæÂÉèÂ§ÑÁêÜÂºÇÂ∏∏
- `UnsupportedFormatError`: ‰∏çÊîØÊåÅÊ†ºÂºèÂºÇÂ∏∏

## ‰æùËµñÈ°π

- `opencv-python >= 4.5.0`
- `numpy >= 1.19.0`

## ËÆ∏ÂèØËØÅ

Êú¨Ê®°ÂùóÈÅµÂæ™È°πÁõÆÁöÑÊï¥‰ΩìËÆ∏ÂèØËØÅ„ÄÇ

# YOLOv8 Postprocessors

This module provides comprehensive postprocessing capabilities for YOLOv8 models, supporting detection, segmentation, and keypoint detection tasks.

## Features

### Supported Tasks
- **Object Detection**: Standard YOLOv8 detection with confidence filtering and NMS
- **Instance Segmentation**: YOLOv8-seg with mask generation from prototypes
- **Keypoint Detection**: YOLOv8-pose with pose validation and keypoint filtering

### Key Capabilities
- Configurable confidence and IoU thresholds
- Non-Maximum Suppression (NMS) filtering
- Coordinate scaling to original image dimensions
- Comprehensive error handling and validation
- Extensible architecture for future enhancements

## Quick Start

### Basic Usage

```python
from hailo_toolbox.process import create_postprocessor, PostprocessConfig

# Create configuration
config = PostprocessConfig(
    num_classes=80,
    det_conf_threshold=0.25,
    nms_iou_threshold=0.5,
    input_shape=(640, 640)
)

# Create postprocessor
postprocessor = create_postprocessor("detection", config)

# Process model outputs
result = postprocessor.postprocess(raw_outputs)
print(f"Detected {len(result)} objects")
```

### Detection Example

```python
# Detection configuration
config = PostprocessConfig(
    num_classes=80,
    det_conf_threshold=0.25,
    nms_iou_threshold=0.5,
    det_max_detections=100,
    input_shape=(640, 640),
    class_names=["person", "bicycle", "car", ...]  # COCO classes
)

postprocessor = create_postprocessor("detection", config)
result = postprocessor.postprocess(raw_outputs, original_shape=(1280, 1280))

# Access results
boxes = result.boxes          # Shape: (N, 4) - [x1, y1, x2, y2]
scores = result.scores        # Shape: (N,) - confidence scores
class_ids = result.class_ids  # Shape: (N,) - class indices
```

### Segmentation Example

```python
# Segmentation configuration
config = PostprocessConfig(
    num_classes=80,
    seg_conf_threshold=0.25,
    seg_mask_threshold=0.5,
    nms_iou_threshold=0.5,
    seg_max_instances=100,
    input_shape=(640, 640)
)

postprocessor = create_postprocessor("segmentation", config)
result = postprocessor.postprocess(raw_outputs)

# Access results
masks = result.masks          # Shape: (N, H, W) - binary masks
boxes = result.boxes          # Shape: (N, 4) - bounding boxes
scores = result.scores        # Shape: (N,) - confidence scores
class_ids = result.class_ids  # Shape: (N,) - class indices
```

### Keypoint Detection Example

```python
# Keypoint configuration
config = PostprocessConfig(
    num_keypoints=17,  # COCO pose format
    kp_conf_threshold=0.25,
    kp_visibility_threshold=0.5,
    nms_iou_threshold=0.5,
    kp_max_persons=100,
    input_shape=(640, 640),
    keypoint_names=[
        "nose", "left_eye", "right_eye", "left_ear", "right_ear",
        "left_shoulder", "right_shoulder", "left_elbow", "right_elbow",
        "left_wrist", "right_wrist", "left_hip", "right_hip",
        "left_knee", "right_knee", "left_ankle", "right_ankle"
    ]
)

postprocessor = create_postprocessor("keypoint", config)
result = postprocessor.postprocess(raw_outputs)

# Access results
keypoints = result.keypoints  # Shape: (N, K, 3) - [x, y, visibility]
boxes = result.boxes          # Shape: (N, 4) - person bounding boxes
scores = result.scores        # Shape: (N,) - person confidence scores
```

## Configuration Options

### PostprocessConfig Parameters

#### Common Parameters
- `input_shape`: Input image dimensions (height, width)
- `nms_iou_threshold`: IoU threshold for NMS (default: 0.5)

#### Detection Parameters
- `num_classes`: Number of object classes
- `det_conf_threshold`: Minimum confidence threshold (default: 0.25)
- `det_max_detections`: Maximum number of detections (default: 300)
- `class_names`: List of class names (optional)

#### Segmentation Parameters
- `seg_conf_threshold`: Minimum confidence threshold (default: 0.25)
- `seg_mask_threshold`: Mask binarization threshold (default: 0.5)
- `seg_max_instances`: Maximum number of instances (default: 100)

#### Keypoint Parameters
- `num_keypoints`: Number of keypoints per person (default: 17)
- `kp_conf_threshold`: Minimum person confidence (default: 0.25)
- `kp_visibility_threshold`: Minimum keypoint visibility (default: 0.5)
- `kp_max_persons`: Maximum number of persons (default: 100)
- `keypoint_names`: List of keypoint names (optional)

## Input Formats

### Detection Input
Expected dictionary with key `"output"` containing array of shape `(N, 4+C)`:
- Columns 0-3: `[x_center, y_center, width, height]`
- Columns 4+: Class confidence scores

### Segmentation Input
Expected dictionary with keys:
- `"output0"`: Detection array of shape `(N, 4+C+M)`
  - Columns 0-3: Bounding box coordinates
  - Columns 4 to 4+C: Class confidence scores
  - Columns 4+C to 4+C+M: Mask coefficients
- `"output1"`: Mask prototypes of shape `(M, H, W)`

### Keypoint Input
Expected dictionary with key `"output"` containing array of shape `(N, 5+K*3)`:
- Columns 0-4: `[x_center, y_center, width, height, person_confidence]`
- Columns 5+: Keypoint data `[x, y, visibility]` for each keypoint

## Output Formats

### DetectionResult
- `boxes`: Bounding boxes in `[x1, y1, x2, y2]` format
- `scores`: Confidence scores
- `class_ids`: Class indices

### SegmentationResult
- `masks`: Binary instance masks
- `boxes`: Bounding boxes
- `scores`: Confidence scores
- `class_ids`: Class indices

### KeypointResult
- `keypoints`: Keypoint coordinates and visibility `[x, y, visibility]`
- `boxes`: Person bounding boxes
- `scores`: Person confidence scores

## Advanced Features

### Coordinate Scaling
Automatically scale coordinates from model input size to original image size:

```python
result = postprocessor.postprocess(raw_outputs, original_shape=(1920, 1080))
```

### Custom Thresholds
Fine-tune detection sensitivity:

```python
# High precision (fewer false positives)
config = PostprocessConfig(det_conf_threshold=0.8, nms_iou_threshold=0.3)

# High recall (fewer missed detections)
config = PostprocessConfig(det_conf_threshold=0.1, nms_iou_threshold=0.7)
```

### Pose Validation
Keypoint postprocessor includes anatomical validation:
- Minimum visible keypoints requirement
- Pose similarity filtering
- Anatomical relationship validation

## Testing

Run the comprehensive test suite:

```bash
python -m pytest hailo_toolbox/process/test_postprocessors.py -v
```

Run example demonstrations:

```bash
python -m hailo_toolbox.process.example_usage
```

## Architecture

### Class Hierarchy
```
BasePostprocessor (Abstract)
‚îú‚îÄ‚îÄ YOLOv8DetPostprocessor
‚îú‚îÄ‚îÄ YOLOv8SegPostprocessor
‚îî‚îÄ‚îÄ YOLOv8KpPostprocessor
```

### Key Components
- **Configuration Management**: Centralized parameter validation
- **Result Classes**: Structured output containers
- **Factory Pattern**: Unified postprocessor creation
- **Error Handling**: Comprehensive validation and logging

## Performance Considerations

- **Vectorized Operations**: NumPy-based processing for efficiency
- **Memory Management**: Efficient array operations and memory reuse
- **Configurable Limits**: Maximum detection/instance limits to control memory usage
- **Early Filtering**: Confidence-based filtering before expensive operations

## Extension Points

The architecture supports easy extension for:
- New YOLOv8 variants (YOLOv8x, YOLOv8n, etc.)
- Custom postprocessing logic
- Additional output formats
- Domain-specific validation rules

## Dependencies

- NumPy: Numerical operations
- SciPy: Advanced mathematical functions
- Logging: Built-in Python logging

## License

This implementation follows the project's licensing terms. 